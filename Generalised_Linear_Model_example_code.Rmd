---
title: "Generalised Linear Models"
author: "Ruth Kelly"
date: "9 January 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Welcome 

This RMarkdown document contains code snippets to accompany the "Session One: Introduction to Linear Modelling" workshop by Dr Ruth Kelly (TCD) & Dr Hannah White (UCD)

This RMarkdown file provides worked examples of Generalised Linear Models for the most common types of ecological data, count data and proportion data. And a further example of a Generalised Linear Mixed Model. 

All datasets needed to conduct the analysis are stored this same github folder as this code file at : https://github.com/Ruth-R-Kelly/GLM_workshop_IEA_2019  or can be automatically loaded in R from packages using the code provided. 

The slides from the presentations given at the workshop are also contained in this folder.
In a single morning and code file, it's impossible to give more the a brief overview of this topic. 


## **Generalised** linear models

### The key difference between *General* Linear Models and **Generalised** Linear Models is that in Generalised Linear Models are designed for use with non-normal response data. 

For these models you must specify an alternative distribution which represents your data (these are known as families):

* Gamma - For non-normal continous data, bounded at zero 
* Binomial - for presence/absence data or proportions 
* Poisson - Count data 
* Negative Binomial - Overdispersed countdata
* Zero-Inflated Poisson/Negative Binomial for data with a lot of zeros. 

Writing these models in R is like writing a linear model except that you use the function 'glm' and must now specify the distribution 'family' and often the link function for that family, for all those listed above 'log' is the most commonly used link function except the Binomial for which a 'logit' link is most commonly used. 

Note: As previously, normality should be judged based on the distribution of the model residuals (not the raw data).

#### Installing required R packages

The following R packages will need to be downloaded in advance of running this code file. They can be installed by removing the '#' symbol infront of the line of code in the code chunk below.


```{r installing packages}
# Install the package 'MASS' on the computer. 
# You will need to remove the # at the start of the next line to run this. 
# install.packages("MASS")
```

#### Loading R packages

Installing R packages downloads 'packages' (essentially sets of functions) onto your computer. When you want to use the functions in a particular package you need to load that package into the R workspace, to do this use the function library().  The next code chunk loads the packages that are needed to run the rest of this code file. 

```{r loading required libraries}
# Load the package 'MASS' into the R workspace
library("MASS")
```

#### Citing R packages

Because you should always do so... (the people who wrote these functions are heros who have made our lives as ecologists a million times easier). They have also made it easy to find the right paper to reference! :)

```{r pressure, echo=FALSE}
# Print the appropriate citation for the package 'MASS'
citation("MASS")
```

## GLMs with Count Data

First example: Amphibian roadkill, (ARR) from Zuur et al. 2009

The data set consists of roadkills of amphibian species at 52 sites along a road in
Portugal. Here, we examine the relationship between distance from a national park,
and the number of amphibians recorded. The variable 'distance from a national park',
is denoted by the column 'D.PARK'. The number of amphibians is denoted by the column 'TOT.N'.

For this workshop example I will only use these two variables, a much more complicated model with many terms could also be fitted depending on the question of interest.

```{r Loading data and examining the dataset}

## Loading in a dataset stored as a .txt file
AAR <- read.table("RoadKills.txt", header = T)

## Show column names
names(AAR)

## Show variable types. 
# Note D.Park is a numeric variable, TOT.N is an integer (i.e. count data whole numbers only)
str(AAR)

## Show summary of all columns - Note: that TOT.N is always above 0
summary(AAR)

## Draw a simple plot of the relationship between parks and number of amphibians

plot( TOT.N~ D.PARK, data = AAR, 
     pch = 16, col = "steelblue")

## Draw a histogram of the response variable, (breaks specifies the number of bars) 
hist(AAR$TOT.N, col = "pink", breaks = 10, 
     main = "Histogram of amphibian counts")

```

First we run a poisson GLM this is the standard first approach for count data.  

The next code chunk runs this GLM and checks for over-dispersion in the residuals. 
If the poisson family is a good choice then we expect 'theta' to be close to 1 and 
not more than 2. If it is more than 2, we can either try adding more predictor variables to the model (not shown here), or account for this over-dispersion using a negative binomial family (shown below).

```{r running a GLM with a poisson family specified}

# function glm, fits a GLM with different family and links specified
mod_ARR <- glm(TOT.N ~ D.PARK, data = AAR, family = "poisson"(link = "log"))
summary(mod_ARR)

#### Check for overdispersion by dividing the residual deviance by the residual df
theta <- mod_ARR$deviance/mod_ARR$df.residual
theta


```

Here, the theta value at 7.8 is much too high indicating that the data is too over-dispersed for a poisson distribution. 

Therefore, we should try using a "negative binomial" family to model the data. 
We do this using the function glm.nb() from the package "MASS".


```{r running a GLM with a poisson negative binomial family }

# glm.nb fits negative binomial family only, therefore no need to 
# specify a negative binomial family in the code

mod_ARR_NB <- glm.nb(TOT.N ~ D.PARK, data = AAR)
summary(mod_ARR_NB)

#### Check for overdispersion by dividing the residual deviance by the residual df
theta <- mod_ARR_NB$deviance/mod_ARR_NB$df.residual
theta

### very close to one.  Negative binomial distribution worked.. 

```

Further model validation.  Now that we have checked for overdispersion and fixed this we should now do a bit more validation. This time looking at the model residuals to see that they show no obvious patterns or heteroscadicity. 

First, we plot the "deviance residuals" against the "fitted values" 
and check that there is pattern in these

Then we plot the "deviance residuals" against each predictor varible in the model. 
In this case there is only one.  Again, we don't want to see any pattern here. 

If you do see an obvious patterns you may need to a) consider non-linear relationships, b) add more explanatory varibles to the model, and/or c) concider using gls or glmm to account for nested structures or non-constant variance. See FAQ for more options here. 

```{r model validation}
#scatterplot of residuals vs fitted values
plot(residuals(mod_ARR_NB, type = "deviance"), fitted(mod_ARR_NB),
     pch = 16, col = "steelblue")

#scatterplot of residuals vs predictor variable
plot(residuals(mod_ARR_NB, type = "deviance"), AAR$D.PARK,
       pch = 16, col = "dark green")

# If you have variables that you have not included, or information of times or spatial locations also plot these against the residual deviance. 

# In this case for example we could see if there's any latitudinal pattern
# in the residuals by plotting them against the column ARR$Y which is the 
# geographic Y coordinates of the data collection points. 

plot(residuals(mod_ARR_NB, type = "deviance"), AAR$Y,
     pch = 16, col = "grey40")

```

Know that we're happy with our model we can look at our summary table and plot our result. 

Here's one example of how to do that, which uses the inbuilt predict function in R.. 
```{r model summary and plot}
summary(mod_ARR_NB)


### predict the results of the model on the original data scale 
# (i.e accounting for the log-link in this case)
pred_ambh <- predict(mod_ARR_NB, type = "response", se.fit = TRUE)
str(pred_ambh)


#### plot the raw data so that the original data can be viewed
plot(AAR$TOT.N~AAR$D.PARK, ylab = "No. of roadkill", xlab = "Distance from park",
     col = "grey30", pch = 16)

### Add predicted number of amphibians from the model
lines(pred_ambh$fit~AAR$D.PARK, type = "l", col = "red", lwd = 1.5)

### Add lines indicating standard error of model estimated means
lines(pred_ambh$fit +pred_ambh$se.fit~AAR$D.PARK, type = "l", col = "blue", lwd = 1, lty = 2) # upper standard error
lines(pred_ambh$fit - pred_ambh$se.fit~AAR$D.PARK, type = "l", col = "blue", lwd = 1, lty = 2) # lower standard error




```


## An example with Presence/Absence data. 

In this example I use a dataset collected accross peatland sites in Nothern Ireland in the year following a severe fire. The data shows the number of Meadow Pipits counted in 10 minute spot counts, one year post fire. The data was collected at 122 locations, accross 6 sites, within each site there were burnt and unburnt locations surveyed.  

For this example, I examine the presence or absence of meadow pipits in burnt and unburnt areas, within three habitat classes. 

```{r Loading data and examining the meadow pipit dataset}

## Loading in a dataset stored as a .csv file
MP <- read.csv("meadow_pipits.csv", header = T)

## show number of rows and columns in the dataset. 
dim(MP)

## Show column names
names(MP)

## Show variable types. 
str(MP)

## Show summary of all columns 
summary(MP)

## show number of burnt and unburnt sites where meadow pipits were observed. 
table(MP$Burnt, MP$MP_Presence)

## Draw a histogram of the response variable, (breaks specifies the number of bars) 
hist(MP$MP_Presence, col = "pink", 
     main = "Histogram meadow pipit data")

```

Here, we run a binomial GLM with a logit link function this is the standard first approach for presence/absence data.  


```{r running a GLM with a binomial family specified}

# function glm, fits a GLM with different family and links specified
mod_MP <- glm(MP_Presence ~ Burnt + Habitat, data = MP, family = "binomial"(link = "logit"))
summary(mod_MP)

### 

```

Checking the the residuals of a binomial GLM (presence/absence) data

1. Examine the deviance residuals, values greater than 2 indicate a lack of fit.   

```{r residual checking in the presence_absence glm}

### extract model residuals and summarise their distribution. 
dev_resid <- resid(mod_MP, type = "deviance")
summary(dev_resid)

```
Here this is fine. 

Examining the model summary shows that there is no significant difference between 
burnt and unburnt areas or between habitat types in terms of the presence or absence of 
meadow pipits. 

A handy trick, in order to get a significance value a categorical variable such as 'habitats' as a whole instead of comparisons between each level, e.g. bog vs dry heath, dry heath vs. wet heath we can run the model with and without the variable habitat and compare the two models using the function 'anova'. When you are running larger models you may find it convenient to do this using the function 'Anova' in the package 'car' 
(e.g. Anova(mod_MP, type = "III")).

```{r model summary for a meadow pipit model}
# print model summary
summary(mod_MP)

# To check the overall significance of the inclusion of habitat as a variable in the model. 

mod_burn_only <- glm(MP_Presence ~ Burnt, data = MP, family = "binomial"(link = "logit"))

### Compare these two models (with and without habitat included)

anova(mod_MP, mod_burn_only, test = "Chisq")

### Here, the p value indicates that there is no significant difference 
### between the models with and without habitat. 

```

## For further reading we recommend 

Books: 
Mixed Effects Models and Extensions in Ecology with R by Zuur et al. 2009

And/or for a more hands on coding approach:
Data Analysis with R statistical software by Thomas et al. 2017

Articles: 

Bolker, et al. 2009. Generalized linear mixed models: a practical guide for    ecology  and evolution. Trends in Ecology & Evolution 24: 127-135.

Zuur AF, Ieno EN, Elphick CS. et al. A protocol for data exploration to avoid common statistical problems. Methods Ecol Evol 1: 3-14

As an online resource with details on almost everything we recommend http://glmm.wikidot.com/ by the inimitable *Ben Bolker*.